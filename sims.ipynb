{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8ad0d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "be171de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_function(candidate, voter):\n",
    "    \"\"\"\n",
    "    Computes the utility as the sum of cube roots of elementwise products.\n",
    "    \n",
    "    ROBUST VERSION: Handles edge cases that cause NaN\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    candidate : array-like\n",
    "        Vector representing candidate position\n",
    "    voter : array-like\n",
    "        Vector representing voter position\n",
    "    epsilon : float, default=1e-10\n",
    "        Small value to prevent numerical issues\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Sum of cube roots of elementwise products (guaranteed not NaN)\n",
    "    \"\"\"\n",
    "    candidate = np.asarray(candidate, dtype=np.float64)\n",
    "    voter = np.asarray(voter, dtype=np.float64)\n",
    "    \n",
    "    # Check for NaN inputs\n",
    "    if np.any(np.isnan(candidate)) or np.any(np.isnan(voter)):\n",
    "        print(f\"WARNING: NaN in input! candidate has {np.sum(np.isnan(candidate))} NaNs, \"\n",
    "              f\"voter has {np.sum(np.isnan(voter))} NaNs\")\n",
    "        return 0.0\n",
    "    \n",
    "    # Elementwise products\n",
    "    products = candidate * voter\n",
    "    \n",
    "    # Cube roots of products (handles negative numbers correctly)\n",
    "    # np.cbrt is better than **(1/3) for negative numbers\n",
    "    cube_roots = np.cbrt(products)\n",
    "    \n",
    "    # Check for NaN in intermediate results\n",
    "    if np.any(np.isnan(cube_roots)):\n",
    "        print(f\"WARNING: NaN in cube_roots! products: {products}\")\n",
    "        # Replace NaNs with 0\n",
    "        cube_roots = np.nan_to_num(cube_roots, nan=0.0)\n",
    "    \n",
    "    # Sum\n",
    "    result = np.sum(cube_roots)\n",
    "    \n",
    "    # Final check\n",
    "    if np.isnan(result):\n",
    "        print(f\"WARNING: NaN in final result! candidate: {candidate}, voter: {voter}\")\n",
    "        return 0.0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f4ff502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_probability(voter_list, voter_index, candidate_list, candidate_index, \n",
    "                               p=0.5, default=False, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Computes the probability of a specific voter voting for a specific candidate.\n",
    "    \n",
    "    ROBUST VERSION: Handles numerical instability in softmax\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    voter_list : array-like\n",
    "        List of voter vectors\n",
    "    voter_index : int\n",
    "        Index of the specific voter\n",
    "    candidate_list : array-like\n",
    "        List of candidate vectors\n",
    "    candidate_index : int\n",
    "        Index of the specific candidate\n",
    "    p : float, default=0.5\n",
    "        Default probability constant (used when default=True)\n",
    "    default : bool, default=False\n",
    "        If True, returns constant probability p.\n",
    "        If False, uses softmax based on utilities.\n",
    "    epsilon : float, default=1e-10\n",
    "        Small value for numerical stability\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Probability of voter voting for candidate (guaranteed in [0, 1])\n",
    "    \"\"\"\n",
    "    if default:\n",
    "        return p\n",
    "    \n",
    "    # Get the specific voter\n",
    "    voter = np.asarray(voter_list[voter_index], dtype=np.float64)\n",
    "    \n",
    "    # Calculate utilities for all candidates\n",
    "    utilities = []\n",
    "    for candidate in candidate_list:\n",
    "        util = utility_function(candidate, voter)\n",
    "        utilities.append(util)\n",
    "    \n",
    "    utilities = np.array(utilities, dtype=np.float64)\n",
    "    \n",
    "    # Check for NaN utilities\n",
    "    if np.any(np.isnan(utilities)):\n",
    "        print(f\"WARNING: NaN utilities in voting_probability for voter {voter_index}\")\n",
    "        print(f\"  utilities: {utilities}\")\n",
    "        # Replace NaNs with very negative number (low probability)\n",
    "        utilities = np.nan_to_num(utilities, nan=-1000.0)\n",
    "    \n",
    "    # Apply softmax with numerical stability\n",
    "    # Subtract max to prevent overflow\n",
    "    max_util = np.max(utilities)\n",
    "    \n",
    "    # Check if max is too large/small\n",
    "    if abs(max_util) > 700:  # exp(700) is near float overflow\n",
    "        print(f\"WARNING: Very large utility values (max={max_util}), rescaling\")\n",
    "        utilities = utilities / (abs(max_util) / 100)  # Rescale\n",
    "        max_util = np.max(utilities)\n",
    "    \n",
    "    exp_utilities = np.exp(utilities - max_util)\n",
    "    \n",
    "    # Check for NaN or inf in exponentials\n",
    "    if np.any(np.isnan(exp_utilities)) or np.any(np.isinf(exp_utilities)):\n",
    "        print(f\"WARNING: NaN/inf in exp(utilities)\")\n",
    "        print(f\"  utilities: {utilities}\")\n",
    "        print(f\"  exp_utilities: {exp_utilities}\")\n",
    "        exp_utilities = np.nan_to_num(exp_utilities, nan=epsilon, posinf=1e10, neginf=epsilon)\n",
    "    \n",
    "    sum_exp = np.sum(exp_utilities)\n",
    "    \n",
    "    # Prevent division by zero\n",
    "    if sum_exp < epsilon:\n",
    "        print(f\"WARNING: Sum of exp_utilities too small: {sum_exp}\")\n",
    "        # Uniform probability as fallback\n",
    "        return 1.0 / len(candidate_list)\n",
    "    \n",
    "    exp_utility_i = exp_utilities[candidate_index]\n",
    "    probability = exp_utility_i / sum_exp\n",
    "    \n",
    "    # Final checks\n",
    "    if np.isnan(probability):\n",
    "        print(f\"WARNING: NaN probability, returning uniform\")\n",
    "        return 1.0 / len(candidate_list)\n",
    "    \n",
    "    # Ensure probability is in valid range\n",
    "    probability = np.clip(probability, 0.0, 1.0)\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "61e37380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_voters(n, d, sparsity=0.5, seed=None):\n",
    "    \"\"\"\n",
    "    Generate n voters with true utility vectors and sparse voting vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n : int\n",
    "        Number of voters\n",
    "    d : int\n",
    "        Number of dimensions (policies)\n",
    "    sparsity : float, default=0.5\n",
    "        Fraction of dimensions to zero out in voting vector (0 = no sparsity, 1 = all zero)\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    true_utility_vectors : ndarray\n",
    "        Shape (n, d) - true utility vectors for each voter (all positive values)\n",
    "    voting_vectors : ndarray\n",
    "        Shape (n, d) - sparse voting vectors (some dimensions zeroed)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Generate true utility vectors (only positive values)\n",
    "    true_utility_vectors = np.random.uniform(0.1, 10.0, size=(n, d))\n",
    "    \n",
    "    # Create sparse voting vectors\n",
    "    voting_vectors = true_utility_vectors.copy()\n",
    "    \n",
    "    # Zero out random dimensions for each voter\n",
    "    for i in range(n):\n",
    "        num_zeros = int(d * sparsity)\n",
    "        zero_indices = np.random.choice(d, size=num_zeros, replace=False)\n",
    "        voting_vectors[i, zero_indices] = 0\n",
    "    \n",
    "    return true_utility_vectors, voting_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "39aeaae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(m, d, budget, seed=None):\n",
    "    \"\"\"\n",
    "    Generate m candidates with policy vectors (budget allocation).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    m : int\n",
    "        Number of candidates\n",
    "    d : int\n",
    "        Number of dimensions (policies)\n",
    "    budget : float\n",
    "        Total budget to allocate across dimensions\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    candidate_vectors : ndarray\n",
    "        Shape (m, d) - policy vectors for each candidate\n",
    "        Each dimension >= -1, and sum(vector) = budget (full budget is used)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    candidate_vectors = np.zeros((m, d))\n",
    "    \n",
    "    for i in range(m):\n",
    "        # Start with all dimensions at -1 (sum = -d)\n",
    "        # Need to add (budget + d) to get sum = budget\n",
    "        # Allocate (budget + d) randomly across dimensions\n",
    "        allocations = np.random.dirichlet(np.ones(d)) * (budget + d)\n",
    "        \n",
    "        # Add to -1 baseline: vector = -1 + allocations\n",
    "        # This ensures: sum(vector) = -d + (budget + d) = budget\n",
    "        # and each vector[i] >= -1 (since allocations[i] >= 0)\n",
    "        candidate_vectors[i] = -1 + allocations\n",
    "    \n",
    "    # Verify budget constraint\n",
    "    for i in range(m):\n",
    "        assert np.all(candidate_vectors[i] >= -1), f\"Candidate {i} violates lower bound\"\n",
    "        assert np.abs(np.sum(candidate_vectors[i]) - budget) < 1e-10, \\\n",
    "            f\"Candidate {i} doesn't use full budget\"\n",
    "    \n",
    "    return candidate_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4714d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_approval_voting_simulation(n, m, d, budget, sparsity=0.5, seed=None):\n",
    "    \"\"\"\n",
    "    Run a complete approval voting simulation using probabilistic voting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n : int\n",
    "        Number of voters\n",
    "    m : int\n",
    "        Number of candidates\n",
    "    d : int\n",
    "        Number of dimensions (policies)\n",
    "    budget : float\n",
    "        Budget for each candidate\n",
    "    sparsity : float, default=0.5\n",
    "        Sparsity of voting vectors (fraction of dimensions zeroed)\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing:\n",
    "        - 'vote_counts': array of vote counts for each candidate\n",
    "        - 'true_utility_vectors': voter true utility vectors\n",
    "        - 'voting_vectors': voter voting vectors\n",
    "        - 'candidate_vectors': candidate policy vectors\n",
    "        - 'approval_matrix': (n, m) boolean matrix of approvals\n",
    "    \"\"\"\n",
    "    # Generate voters\n",
    "    true_utility_vectors, voting_vectors = generate_voters(n, d, sparsity, seed)\n",
    "    \n",
    "    # Generate candidates\n",
    "    candidate_vectors = generate_candidates(m, d, budget, seed)\n",
    "    \n",
    "    # Convert to lists for voting_probability function\n",
    "    voting_vectors_list = [voting_vectors[i] for i in range(n)]\n",
    "    candidate_vectors_list = [candidate_vectors[i] for i in range(m)]\n",
    "    \n",
    "    # Determine approvals using probabilistic voting\n",
    "    approval_matrix = np.zeros((n, m), dtype=bool)\n",
    "    \n",
    "    for voter_idx in range(n):\n",
    "        for candidate_idx in range(m):\n",
    "            # Get voting probability using softmax\n",
    "            prob = voting_probability(\n",
    "                voting_vectors_list, \n",
    "                voter_index=voter_idx,\n",
    "                candidate_list=candidate_vectors_list,\n",
    "                candidate_index=candidate_idx,\n",
    "                default=False\n",
    "            )\n",
    "            \n",
    "            # Toss weighted coin: approve with probability prob\n",
    "            approval = np.random.rand() < prob\n",
    "            approval_matrix[voter_idx, candidate_idx] = approval\n",
    "    \n",
    "    # Count votes for each candidate\n",
    "    vote_counts = np.sum(approval_matrix, axis=0)\n",
    "    \n",
    "    results = {\n",
    "        'vote_counts': vote_counts,\n",
    "        'true_utility_vectors': true_utility_vectors,\n",
    "        'voting_vectors': voting_vectors,\n",
    "        'candidate_vectors': candidate_vectors,\n",
    "        'approval_matrix': approval_matrix\n",
    "    }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "79b03704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_winner_and_compute_global_utility(vote_counts, candidate_vectors, true_utility_vectors, k, seed=None):\n",
    "    \"\"\"\n",
    "    Select winner from top k candidates and compute global utility.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    vote_counts : array-like\n",
    "        Vote counts for each candidate\n",
    "    candidate_vectors : array-like\n",
    "        Policy vectors for each candidate\n",
    "    true_utility_vectors : array-like\n",
    "        True utility vectors for each voter\n",
    "    k : int\n",
    "        Number of top candidates to consider\n",
    "    seed : int, optional\n",
    "        Random seed for winner selection\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    winner_idx : int\n",
    "        Index of the winning candidate\n",
    "    global_utility : float\n",
    "        Sum of utilities across all voters for the winner\n",
    "    top_k_indices : array\n",
    "        Indices of the top k candidates\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    vote_counts = np.asarray(vote_counts)\n",
    "    \n",
    "    # Find top k candidates (handle ties by taking first k)\n",
    "    # Sort indices by vote count in descending order\n",
    "    sorted_indices = np.argsort(vote_counts)[::-1]\n",
    "    top_k_indices = sorted_indices[:k]\n",
    "    \n",
    "    # Randomly select winner from top k (uniform probability 1/k)\n",
    "    winner_idx = np.random.choice(top_k_indices)\n",
    "    \n",
    "    # Calculate global utility using true utility vectors\n",
    "    winner_vector = candidate_vectors[winner_idx]\n",
    "    global_utility = 0.0\n",
    "    \n",
    "    for voter_idx in range(len(true_utility_vectors)):\n",
    "        true_utility_vector = true_utility_vectors[voter_idx]\n",
    "        voter_utility = utility_function(winner_vector, true_utility_vector)\n",
    "        global_utility += voter_utility\n",
    "    \n",
    "    return winner_idx, global_utility, top_k_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8bcfd76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_expected_global_utility_by_k(n, m, d, budget, sparsity=0.5, n_simulations=100, seed=None):\n",
    "    \"\"\"\n",
    "    Estimate expected global utility for each k (1 to m) using Monte Carlo simulation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n : int\n",
    "        Number of voters\n",
    "    m : int\n",
    "        Number of candidates\n",
    "    d : int\n",
    "        Number of dimensions\n",
    "    budget : float\n",
    "        Budget for each candidate\n",
    "    sparsity : float, default=0.5\n",
    "        Sparsity of voting vectors\n",
    "    n_simulations : int, default=100\n",
    "        Number of Monte Carlo simulations to run\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    expected_utilities : dict\n",
    "        Dictionary mapping k -> expected global utility\n",
    "    std_utilities : dict\n",
    "        Dictionary mapping k -> standard deviation of global utility\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Store utilities for each k across all simulations\n",
    "    utilities_by_k = {k: [] for k in range(1, m + 1)}\n",
    "    \n",
    "    for sim in range(n_simulations):\n",
    "        # Run simulation with different seed for each run\n",
    "        results = run_approval_voting_simulation(\n",
    "            n=n, m=m, d=d, budget=budget, sparsity=sparsity, seed=None\n",
    "        )\n",
    "        \n",
    "        # For each possible k, compute expected global utility\n",
    "        vote_counts = results['vote_counts']\n",
    "        candidate_vectors = results['candidate_vectors']\n",
    "        true_utility_vectors = results['true_utility_vectors']\n",
    "        \n",
    "        # Sort candidates by vote count\n",
    "        sorted_indices = np.argsort(vote_counts)[::-1]\n",
    "        \n",
    "        # For each k, compute expected utility\n",
    "        for k in range(1, m + 1):\n",
    "            top_k_indices = sorted_indices[:k]\n",
    "            \n",
    "            # Expected utility = average utility of top k candidates\n",
    "            # (since winner is randomly selected with probability 1/k)\n",
    "            expected_utility = 0.0\n",
    "            for candidate_idx in top_k_indices:\n",
    "                candidate_vector = candidate_vectors[candidate_idx]\n",
    "                global_utility = 0.0\n",
    "                \n",
    "                for voter_idx in range(len(true_utility_vectors)):\n",
    "                    true_utility_vector = true_utility_vectors[voter_idx]\n",
    "                    voter_utility = utility_function(candidate_vector, true_utility_vector)\n",
    "                    global_utility += voter_utility\n",
    "                \n",
    "                expected_utility += global_utility / k  # Each has probability 1/k\n",
    "            \n",
    "            utilities_by_k[k].append(expected_utility)\n",
    "    \n",
    "    # Compute means and standard deviations\n",
    "    expected_utilities = {k: np.mean(utilities_by_k[k]) for k in range(1, m + 1)}\n",
    "    std_utilities = {k: np.std(utilities_by_k[k]) for k in range(1, m + 1)}\n",
    "    \n",
    "    return expected_utilities, std_utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f10d70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_k(n, m, d, budget, sparsity=0.5, n_simulations=100, seed=None):\n",
    "    \"\"\"\n",
    "    Find the optimal k that maximizes expected global utility.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n : int\n",
    "        Number of voters\n",
    "    m : int\n",
    "        Number of candidates\n",
    "    d : int\n",
    "        Number of dimensions\n",
    "    budget : float\n",
    "        Budget for each candidate\n",
    "    sparsity : float, default=0.5\n",
    "        Sparsity of voting vectors\n",
    "    n_simulations : int, default=100\n",
    "        Number of Monte Carlo simulations to run\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    optimal_k : int\n",
    "        The value of k that maximizes expected global utility\n",
    "    expected_utilities : dict\n",
    "        Dictionary mapping k -> expected global utility\n",
    "    std_utilities : dict\n",
    "        Dictionary mapping k -> standard deviation of global utility\n",
    "    \"\"\"\n",
    "    expected_utilities, std_utilities = estimate_expected_global_utility_by_k(\n",
    "        n, m, d, budget, sparsity, n_simulations, seed\n",
    "    )\n",
    "    \n",
    "    # Find k with maximum expected utility\n",
    "    optimal_k = max(expected_utilities, key=expected_utilities.get)\n",
    "    \n",
    "    return optimal_k, expected_utilities, std_utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a3a381a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_gradient(candidate, voter, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Compute the gradient of utility with respect to candidate position.\n",
    "    \n",
    "    ROBUST VERSION: Prevents division by zero and NaN propagation\n",
    "    \n",
    "    The derivative of cbrt(x) = (1/3) * x^(-2/3) = (1/3) / x^(2/3)\n",
    "    For products close to zero, this explodes, so we clip it.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    candidate : array-like\n",
    "        Candidate policy vector\n",
    "    voter : array-like\n",
    "        Voter vector\n",
    "    epsilon : float, default=1e-8\n",
    "        Threshold for considering products as zero\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    gradient : ndarray\n",
    "        Gradient of utility w.r.t. candidate position (guaranteed not NaN)\n",
    "    \"\"\"\n",
    "    candidate = np.asarray(candidate, dtype=np.float64)\n",
    "    voter = np.asarray(voter, dtype=np.float64)\n",
    "    \n",
    "    # Check for NaN inputs\n",
    "    if np.any(np.isnan(candidate)) or np.any(np.isnan(voter)):\n",
    "        print(f\"WARNING: NaN in gradient input!\")\n",
    "        return np.zeros_like(candidate)\n",
    "    \n",
    "    products = candidate * voter\n",
    "    gradient = np.zeros_like(candidate, dtype=np.float64)\n",
    "    \n",
    "    for k in range(len(candidate)):\n",
    "        # Skip if voter component is zero (gradient is zero)\n",
    "        if abs(voter[k]) < epsilon:\n",
    "            gradient[k] = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Handle near-zero products carefully\n",
    "        if abs(products[k]) < epsilon:\n",
    "            # Near zero, gradient is very large but we clip it\n",
    "            # Sign depends on sign of voter[k]\n",
    "            gradient[k] = np.sign(voter[k]) * 1000.0  # Clipped large value\n",
    "            continue\n",
    "        \n",
    "        # Normal case: d/dc[k] cbrt(c[k] * v[k]) = (1/3) * v[k] / (c[k] * v[k])^(2/3)\n",
    "        # Use sign-preserving power for negative products\n",
    "        sign = np.sign(products[k])\n",
    "        abs_product = abs(products[k])\n",
    "        \n",
    "        # Compute x^(-2/3) = 1 / x^(2/3) safely\n",
    "        power_term = abs_product ** (2.0/3.0)\n",
    "        \n",
    "        if power_term < epsilon:\n",
    "            # Very small denominator, clip gradient\n",
    "            gradient[k] = np.sign(voter[k]) * 1000.0\n",
    "        else:\n",
    "            gradient[k] = (1.0/3.0) * voter[k] / (sign * power_term)\n",
    "    \n",
    "    # Final NaN check\n",
    "    if np.any(np.isnan(gradient)):\n",
    "        print(f\"WARNING: NaN in gradient output! Replacing with zeros.\")\n",
    "        print(f\"  candidate: {candidate}\")\n",
    "        print(f\"  voter: {voter}\")\n",
    "        print(f\"  products: {products}\")\n",
    "        gradient = np.nan_to_num(gradient, nan=0.0, posinf=1000.0, neginf=-1000.0)\n",
    "    \n",
    "    # Clip extremely large gradients\n",
    "    gradient = np.clip(gradient, -1000.0, 1000.0)\n",
    "    \n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "37bf8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_win_probability_gradient(candidate_idx, candidate_vectors, voting_vectors, k, n_samples=100):\n",
    "    \"\"\"\n",
    "    Compute the gradient of (P(in top k) * 1/k) for a candidate.\n",
    "    \n",
    "    This is the expected value of winning: if candidate is in top k, they have 1/k chance.\n",
    "    \n",
    "    Uses Monte Carlo sampling to estimate the probability and its gradient.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    candidate_idx : int\n",
    "        Index of the candidate\n",
    "    candidate_vectors : array-like, shape (m, d)\n",
    "        All candidate policy vectors\n",
    "    voting_vectors : array-like, shape (n, d)\n",
    "        Voting vectors for all voters\n",
    "    k : int\n",
    "        Number of top candidates to consider\n",
    "    n_samples : int, default=100\n",
    "        Number of Monte Carlo samples for gradient estimation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    gradient : ndarray\n",
    "        Gradient of (P(in top k) * 1/k) w.r.t. candidate position\n",
    "    \"\"\"\n",
    "    candidate_vectors = np.asarray(candidate_vectors)\n",
    "    voting_vectors = np.asarray(voting_vectors)\n",
    "    candidate = candidate_vectors[candidate_idx]\n",
    "    n_voters = len(voting_vectors)\n",
    "    m_candidates = len(candidate_vectors)\n",
    "    \n",
    "    # Convert to lists for voting_probability\n",
    "    voting_vectors_list = [voting_vectors[i] for i in range(n_voters)]\n",
    "    candidate_vectors_list = [candidate_vectors[i] for i in range(m_candidates)]\n",
    "    \n",
    "    # Compute approval probabilities for all candidate-voter pairs\n",
    "    approval_probs = np.zeros((n_voters, m_candidates))\n",
    "    for voter_idx in range(n_voters):\n",
    "        for cand_idx in range(m_candidates):\n",
    "            approval_probs[voter_idx, cand_idx] = voting_probability(\n",
    "                voting_vectors_list,\n",
    "                voter_index=voter_idx,\n",
    "                candidate_list=candidate_vectors_list,\n",
    "                candidate_index=cand_idx,\n",
    "                default=False\n",
    "            )\n",
    "    \n",
    "    # Use finite differences with small perturbations\n",
    "    epsilon = 1e-5\n",
    "    gradient = np.zeros_like(candidate)\n",
    "    \n",
    "    # Estimate gradient using finite differences\n",
    "    for dim in range(len(candidate)):\n",
    "        # Perturb candidate position\n",
    "        candidate_perturbed = candidate.copy()\n",
    "        candidate_perturbed[dim] += epsilon\n",
    "        \n",
    "        # Create perturbed candidate vectors\n",
    "        candidate_vectors_perturbed = candidate_vectors.copy()\n",
    "        candidate_vectors_perturbed[candidate_idx] = candidate_perturbed\n",
    "        candidate_vectors_list_perturbed = [candidate_vectors_perturbed[i] for i in range(m_candidates)]\n",
    "        \n",
    "        # Recompute approval probabilities with perturbation\n",
    "        approval_probs_perturbed = np.zeros((n_voters, m_candidates))\n",
    "        for voter_idx in range(n_voters):\n",
    "            for cand_idx in range(m_candidates):\n",
    "                approval_probs_perturbed[voter_idx, cand_idx] = voting_probability(\n",
    "                    voting_vectors_list,\n",
    "                    voter_index=voter_idx,\n",
    "                    candidate_list=candidate_vectors_list_perturbed,\n",
    "                    candidate_index=cand_idx,\n",
    "                    default=False\n",
    "                )\n",
    "        \n",
    "        # Monte Carlo estimate of P(in top k) for original and perturbed\n",
    "        prob_original = estimate_top_k_probability(approval_probs, candidate_idx, k, n_samples)\n",
    "        prob_perturbed = estimate_top_k_probability(approval_probs_perturbed, candidate_idx, k, n_samples)\n",
    "        \n",
    "        # Finite difference gradient\n",
    "        # The objective is P(in top k) * (1/k) = expected probability of winning\n",
    "        gradient[dim] = (prob_perturbed - prob_original) / epsilon * (1.0 / k)\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "\n",
    "def estimate_top_k_probability(approval_probs, candidate_idx, k, n_samples=100):\n",
    "    \"\"\"\n",
    "    Estimate P(candidate is in top k) using Monte Carlo sampling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    approval_probs : ndarray, shape (n_voters, m_candidates)\n",
    "        Probability each voter approves each candidate\n",
    "    candidate_idx : int\n",
    "        Index of candidate of interest\n",
    "    k : int\n",
    "        Number of top candidates\n",
    "    n_samples : int, default=100\n",
    "        Number of Monte Carlo samples\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    probability : float\n",
    "        Estimated probability candidate is in top k\n",
    "    \"\"\"\n",
    "    n_voters, m_candidates = approval_probs.shape\n",
    "    in_top_k_count = 0\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # Sample vote counts: for each voter-candidate pair, sample approval\n",
    "        vote_counts = np.zeros(m_candidates)\n",
    "        for voter_idx in range(n_voters):\n",
    "            for cand_idx in range(m_candidates):\n",
    "                if np.random.rand() < approval_probs[voter_idx, cand_idx]:\n",
    "                    vote_counts[cand_idx] += 1\n",
    "        \n",
    "        # Check if candidate is in top k\n",
    "        sorted_indices = np.argsort(vote_counts)[::-1]\n",
    "        top_k_indices = sorted_indices[:k]\n",
    "        if candidate_idx in top_k_indices:\n",
    "            in_top_k_count += 1\n",
    "    \n",
    "    return in_top_k_count / n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3211b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_approval_gradient(candidate_idx, candidate_vectors, voting_vectors):\n",
    "    \"\"\"\n",
    "    Compute the gradient of expected approval votes for a candidate.\n",
    "    \n",
    "    The expected approval votes = sum over voters of P(voter approves candidate)\n",
    "    where P(voter approves candidate) is given by voting_probability (softmax).\n",
    "    \n",
    "    Why we need utility_gradient:\n",
    "    - P depends on utility: P = softmax(utilities) = exp(u_i) / sum(exp(u_j))\n",
    "    - Utility depends on candidate position: u_i = utility_function(candidate, voter)\n",
    "    - To get dP/dc, we use the chain rule: dP/dc = (dP/du) * (du/dc)\n",
    "      where:\n",
    "      - dP/du = p_i * (1 - p_i) (derivative of softmax)\n",
    "      - du/dc = utility_gradient (derivative of utility function)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    candidate_idx : int\n",
    "        Index of the candidate\n",
    "    candidate_vectors : array-like, shape (m, d)\n",
    "        All candidate policy vectors\n",
    "    voting_vectors : array-like, shape (n, d)\n",
    "        Voting vectors for all voters\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    gradient : ndarray\n",
    "        Gradient of expected approval votes w.r.t. candidate position\n",
    "    \"\"\"\n",
    "    candidate_vectors = np.asarray(candidate_vectors)\n",
    "    voting_vectors = np.asarray(voting_vectors)\n",
    "    candidate = candidate_vectors[candidate_idx]\n",
    "    \n",
    "    n_voters = len(voting_vectors)\n",
    "    gradient = np.zeros_like(candidate)\n",
    "    \n",
    "    # Convert to lists for voting_probability function\n",
    "    voting_vectors_list = [voting_vectors[i] for i in range(n_voters)]\n",
    "    candidate_vectors_list = [candidate_vectors[i] for i in range(len(candidate_vectors))]\n",
    "    \n",
    "    for voter_idx in range(n_voters):\n",
    "        voter = voting_vectors[voter_idx]\n",
    "        \n",
    "        # Get the voting probability using the same function as in simulation\n",
    "        # This is P(voter approves candidate) = softmax probability\n",
    "        p_i = voting_probability(\n",
    "            voting_vectors_list,\n",
    "            voter_index=voter_idx,\n",
    "            candidate_list=candidate_vectors_list,\n",
    "            candidate_index=candidate_idx,\n",
    "            default=False\n",
    "        )\n",
    "        \n",
    "        # CHAIN RULE: To compute dP/dc, we need:\n",
    "        # 1. dP/du = how probability changes with utility (softmax derivative)\n",
    "        # 2. du/dc = how utility changes with candidate position (utility_gradient)\n",
    "        # Then: dP/dc = (dP/du) * (du/dc) = p_i * (1 - p_i) * du_i/dc\n",
    "        \n",
    "        # Step 1: dP/du for softmax is p_i * (1 - p_i)\n",
    "        # (This is the derivative of softmax probability w.r.t. its own utility)\n",
    "        \n",
    "        # Step 2: du/dc = how utility changes when we change candidate position\n",
    "        # This is what utility_gradient computes\n",
    "        du_i_dc = utility_gradient(candidate, voter)\n",
    "        \n",
    "        # Apply chain rule: dP/dc = (dP/du) * (du/dc)\n",
    "        dp_i_dc = p_i * (1 - p_i) * du_i_dc\n",
    "        \n",
    "        # Gradient of expected approval: sum over voters of dp_i/dc\n",
    "        gradient += dp_i_dc\n",
    "    \n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "06cc06dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_constraints(candidate, budget, lower_bound=-1.0, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Project a candidate vector to satisfy budget and lower bound constraints.\n",
    "    \n",
    "    ROBUST VERSION: Ensures numerical stability and valid outputs\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    candidate : array-like\n",
    "        Candidate policy vector\n",
    "    budget : float\n",
    "        Budget constraint (sum of vector must equal this)\n",
    "    lower_bound : float, default=-1.0\n",
    "        Lower bound for each dimension\n",
    "    epsilon : float, default=1e-6\n",
    "        Tolerance for constraint satisfaction\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    projected : ndarray\n",
    "        Projected candidate vector satisfying constraints (guaranteed not NaN)\n",
    "    \"\"\"\n",
    "    candidate = np.asarray(candidate, dtype=np.float64)\n",
    "    \n",
    "    # Check for NaN inputs\n",
    "    if np.any(np.isnan(candidate)):\n",
    "        print(f\"WARNING: NaN in project_to_constraints input, using uniform allocation\")\n",
    "        d = len(candidate)\n",
    "        return np.full(d, lower_bound + (budget - lower_bound * d) / d)\n",
    "    \n",
    "    d = len(candidate)\n",
    "    \n",
    "    # First, enforce lower bound\n",
    "    candidate = np.maximum(candidate, lower_bound)\n",
    "    \n",
    "    # Then, adjust to satisfy budget constraint\n",
    "    current_sum = np.sum(candidate)\n",
    "    \n",
    "    if np.isnan(current_sum):\n",
    "        print(f\"WARNING: NaN in current_sum during projection\")\n",
    "        return np.full(d, lower_bound + (budget - lower_bound * d) / d)\n",
    "    \n",
    "    if abs(current_sum - budget) > epsilon:\n",
    "        # Amount to adjust\n",
    "        diff = budget - current_sum\n",
    "        \n",
    "        # Find dimensions that can be adjusted (those above lower bound)\n",
    "        adjustable = candidate > (lower_bound + epsilon)\n",
    "        n_adjustable = np.sum(adjustable)\n",
    "        \n",
    "        if n_adjustable > 0:\n",
    "            # Distribute the difference proportionally\n",
    "            current_values = candidate[adjustable]\n",
    "            if np.sum(current_values) > epsilon:\n",
    "                # Proportional adjustment\n",
    "                adjustment_weights = current_values / np.sum(current_values)\n",
    "                candidate[adjustable] += diff * adjustment_weights\n",
    "            else:\n",
    "                # Uniform adjustment\n",
    "                candidate[adjustable] += diff / n_adjustable\n",
    "            \n",
    "            # Re-enforce lower bound\n",
    "            candidate = np.maximum(candidate, lower_bound)\n",
    "        else:\n",
    "            # All at lower bound, distribute remaining budget uniformly\n",
    "            remaining = budget - d * lower_bound\n",
    "            if remaining > 0:\n",
    "                candidate = np.full(d, lower_bound + remaining / d)\n",
    "            else:\n",
    "                print(f\"WARNING: Budget {budget} cannot satisfy {d} dims at lower bound {lower_bound}\")\n",
    "                candidate = np.full(d, lower_bound)\n",
    "    \n",
    "    # Final verification\n",
    "    final_sum = np.sum(candidate)\n",
    "    if abs(final_sum - budget) > epsilon:\n",
    "        print(f\"WARNING: Projection failed to satisfy budget: {final_sum} vs {budget}\")\n",
    "        # Force correction\n",
    "        candidate = candidate * (budget / final_sum) if final_sum > epsilon else np.full(d, budget / d)\n",
    "    \n",
    "    # Check for NaN in output\n",
    "    if np.any(np.isnan(candidate)):\n",
    "        print(f\"WARNING: NaN in projection output, using uniform allocation\")\n",
    "        return np.full(d, lower_bound + (budget - lower_bound * d) / d)\n",
    "    \n",
    "    return candidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cbc037ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_candidates(candidate_vectors, voting_vectors, budget, k, learning_rate=0.1, \n",
    "                        convergence_threshold=1e-2, max_iterations=1000, seed=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Optimize candidate positions using gradient descent to maximize P(in top k) * (1/k).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    candidate_vectors : array-like, shape (m, d)\n",
    "        Initial candidate policy vectors\n",
    "    voting_vectors : array-like, shape (n, d)\n",
    "        Voting vectors for all voters\n",
    "    budget : float\n",
    "        Budget constraint for each candidate\n",
    "    k : int\n",
    "        Number of top candidates (candidates optimize for P(in top k) * 1/k)\n",
    "    learning_rate : float, default=0.1\n",
    "        Learning rate for gradient descent\n",
    "    convergence_threshold : float, default=1e-2\n",
    "        Convergence threshold (gradient magnitude)\n",
    "    max_iterations : int, default=1000\n",
    "        Maximum number of iterations per candidate\n",
    "    seed : int, optional\n",
    "        Random seed for candidate ordering\n",
    "    verbose : bool, default=True\n",
    "        Whether to print progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    optimized_vectors : ndarray\n",
    "        Optimized candidate policy vectors\n",
    "    history : list\n",
    "        List of candidate vectors at each iteration\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    candidate_vectors = np.asarray(candidate_vectors).copy()\n",
    "    voting_vectors = np.asarray(voting_vectors)\n",
    "    m_candidates, d_dimensions = candidate_vectors.shape\n",
    "    \n",
    "    # Random ordering of candidates\n",
    "    candidate_order = np.random.permutation(m_candidates)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Optimizing {m_candidates} candidates for top-{k} selection...\")\n",
    "        print(f\"Order: {candidate_order + 1}\")  # 1-indexed for display\n",
    "    \n",
    "    history = [candidate_vectors.copy()]\n",
    "    converged = np.zeros(m_candidates, dtype=bool)\n",
    "    \n",
    "    iteration = 0\n",
    "    while not np.all(converged) and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        any_update = False\n",
    "        \n",
    "        for candidate_idx in candidate_order:\n",
    "            if converged[candidate_idx]:\n",
    "                continue\n",
    "            \n",
    "            # Compute gradient using top-k win probability\n",
    "            gradient = top_k_win_probability_gradient(\n",
    "                candidate_idx, candidate_vectors, voting_vectors, k\n",
    "            )\n",
    "            \n",
    "            # Check convergence\n",
    "            gradient_magnitude = np.linalg.norm(gradient)\n",
    "            if gradient_magnitude < convergence_threshold:\n",
    "                converged[candidate_idx] = True\n",
    "                continue\n",
    "            \n",
    "            # Update candidate position\n",
    "            candidate_vectors[candidate_idx] += learning_rate * gradient\n",
    "            \n",
    "            # Project to constraints\n",
    "            candidate_vectors[candidate_idx] = project_to_constraints(\n",
    "                candidate_vectors[candidate_idx], budget\n",
    "            )\n",
    "            \n",
    "            any_update = True\n",
    "        \n",
    "        if any_update:\n",
    "            history.append(candidate_vectors.copy())\n",
    "        \n",
    "        if verbose and iteration % 100 == 0:\n",
    "            n_converged = np.sum(converged)\n",
    "            print(f\"Iteration {iteration}: {n_converged}/{m_candidates} candidates converged\")\n",
    "    \n",
    "    if verbose:\n",
    "        if np.all(converged):\n",
    "            print(f\"All candidates converged after {iteration} iterations\")\n",
    "        else:\n",
    "            print(f\"Stopped after {max_iterations} iterations ({np.sum(converged)}/{m_candidates} converged)\")\n",
    "    \n",
    "    return candidate_vectors, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f951015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_with_optimization_all_k(voting_vectors, true_utility_vectors, n_candidates, budget,\n",
    "                                           n_simulations=1000, learning_rate=0.1, convergence_threshold=1e-2,\n",
    "                                           max_iterations=1000, optimization_seed=None, simulation_seed=None, \n",
    "                                           verbose=True):\n",
    "    \"\"\"\n",
    "    Run simulation with optimization for ALL values of k, then report expected global utility for each k.\n",
    "    \n",
    "    For each k from 1 to m:\n",
    "    1. Optimize candidates to maximize P(in top k) * (1/k)\n",
    "    2. Run simulations to compute expected global utility when winner is randomly selected from top k\n",
    "    \n",
    "    FIXED: Now randomly selects ONE winner from top-k instead of averaging over all top-k candidates.\n",
    "    This gives non-zero variance even when the same candidates are always in top-k.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    voting_vectors : array-like, shape (n_voters, d_dimensions)\n",
    "        Voting vectors for each voter\n",
    "    true_utility_vectors : array-like, shape (n_voters, d_dimensions)\n",
    "        True utility vectors for each voter\n",
    "    n_candidates : int\n",
    "        Number of candidates\n",
    "    budget : float\n",
    "        Budget constraint for each candidate\n",
    "    n_simulations : int, default=1000\n",
    "        Number of simulations for expected utility calculation\n",
    "    learning_rate : float, default=0.1\n",
    "        Learning rate for gradient descent\n",
    "    convergence_threshold : float, default=1e-2\n",
    "        Convergence threshold for optimization\n",
    "    max_iterations : int, default=1000\n",
    "        Maximum iterations for optimization\n",
    "    optimization_seed : int, optional\n",
    "        Random seed for candidate initialization and ordering\n",
    "    simulation_seed : int, optional\n",
    "        Random seed for simulation\n",
    "    verbose : bool, default=True\n",
    "        Whether to print progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_by_k : dict\n",
    "        Dictionary mapping k -> results for that k value\n",
    "        Each results dict contains:\n",
    "        - 'optimized_candidates': optimized candidate vectors\n",
    "        - 'expected_utility': expected global utility (mean across simulations)\n",
    "        - 'std_utility': standard deviation (now non-zero!)\n",
    "        - 'all_utilities': all utility values from simulations\n",
    "    \"\"\"\n",
    "    voting_vectors = np.asarray(voting_vectors)\n",
    "    true_utility_vectors = np.asarray(true_utility_vectors)\n",
    "    n_voters, d_dimensions = voting_vectors.shape\n",
    "    \n",
    "    results_by_k = {}\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"OPTIMIZATION FOR ALL K VALUES\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Voters: {n_voters}, Candidates: {n_candidates}, Dimensions: {d_dimensions}\")\n",
    "        print(f\"Budget: {budget}\")\n",
    "        print()\n",
    "    \n",
    "    for k in range(1, n_candidates + 1):\n",
    "        if verbose:\n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(f\"K = {k}\")\n",
    "            print(f\"{'=' * 60}\\n\")\n",
    "        \n",
    "        # Initialize candidates randomly (same seed for each k for fair comparison)\n",
    "        if optimization_seed is not None:\n",
    "            np.random.seed(optimization_seed)\n",
    "        \n",
    "        initial_candidates = generate_candidates(n_candidates, d_dimensions, budget, seed=optimization_seed)\n",
    "        \n",
    "        # Optimize candidates for this k\n",
    "        optimized_candidates, _ = optimize_candidates(\n",
    "            initial_candidates,\n",
    "            voting_vectors,\n",
    "            budget,\n",
    "            k=k,\n",
    "            learning_rate=learning_rate,\n",
    "            convergence_threshold=convergence_threshold,\n",
    "            max_iterations=max_iterations,\n",
    "            seed=optimization_seed,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Run simulations with optimized candidates\n",
    "        if verbose:\n",
    "            print(f\"\\nRunning {n_simulations} simulations for k={k}...\")\n",
    "        \n",
    "        # Set simulation seed if provided\n",
    "        if simulation_seed is not None:\n",
    "            np.random.seed(simulation_seed)\n",
    "        \n",
    "        utilities = []\n",
    "        for sim in range(n_simulations):\n",
    "            # Run probabilistic voting\n",
    "            approval_matrix = np.zeros((n_voters, n_candidates), dtype=bool)\n",
    "            voting_vectors_list = [voting_vectors[i] for i in range(n_voters)]\n",
    "            candidate_vectors_list = [optimized_candidates[i] for i in range(n_candidates)]\n",
    "            \n",
    "            for voter_idx in range(n_voters):\n",
    "                for candidate_idx in range(n_candidates):\n",
    "                    prob = voting_probability(\n",
    "                        voting_vectors_list, \n",
    "                        voter_index=voter_idx,\n",
    "                        candidate_list=candidate_vectors_list,\n",
    "                        candidate_index=candidate_idx,\n",
    "                        default=False\n",
    "                    )\n",
    "                    approval = np.random.rand() < prob\n",
    "                    approval_matrix[voter_idx, candidate_idx] = approval\n",
    "            \n",
    "            vote_counts = np.sum(approval_matrix, axis=0)\n",
    "            \n",
    "            # Get top k candidates\n",
    "            sorted_indices = np.argsort(vote_counts)[::-1]\n",
    "            top_k_indices = sorted_indices[:k]\n",
    "            \n",
    "            # ============================================================\n",
    "            # FIXED: Randomly select ONE winner from top-k\n",
    "            # (Instead of averaging over all top-k candidates)\n",
    "            # ============================================================\n",
    "            winner_idx = np.random.choice(top_k_indices)\n",
    "            \n",
    "            # Compute actual global utility for THIS winner\n",
    "            winner_vector = optimized_candidates[winner_idx]\n",
    "            global_utility = 0.0\n",
    "            \n",
    "            for voter_idx in range(n_voters):\n",
    "                true_utility_vector = true_utility_vectors[voter_idx]\n",
    "                voter_utility = utility_function(winner_vector, true_utility_vector)\n",
    "                global_utility += voter_utility\n",
    "            \n",
    "            # Store the actual utility (not expected utility)\n",
    "            utilities.append(global_utility)\n",
    "        \n",
    "        # Store results\n",
    "        results_by_k[k] = {\n",
    "            'optimized_candidates': optimized_candidates,\n",
    "            'expected_utility': np.mean(utilities),\n",
    "            'std_utility': np.std(utilities),\n",
    "            'all_utilities': utilities\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Expected global utility for k={k}: {np.mean(utilities):.4f}  {np.std(utilities):.4f}\")\n",
    "    \n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(\"SUMMARY: Expected Global Utility by K\")\n",
    "        print(f\"{'=' * 60}\\n\")\n",
    "        \n",
    "        optimal_k = max(results_by_k.keys(), key=lambda k: results_by_k[k]['expected_utility'])\n",
    "        \n",
    "        for k in range(1, n_candidates + 1):\n",
    "            marker = \" <-- OPTIMAL\" if k == optimal_k else \"\"\n",
    "            print(f\"k={k}: {results_by_k[k]['expected_utility']:.4f}  {results_by_k[k]['std_utility']:.4f}{marker}\")\n",
    "    \n",
    "    return results_by_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "40f62dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval Voting Simulation Results\n",
      "==================================================\n",
      "Voters: 20, Candidates: 5, Dimensions: 10\n",
      "Budget per candidate: 20.0, Voting vector sparsity: 0.4\n",
      "\n",
      "Vote counts for each candidate:\n",
      "  Candidate 1: 3 votes (15.0% approval rate)\n",
      "  Candidate 2: 3 votes (15.0% approval rate)\n",
      "  Candidate 3: 9 votes (45.0% approval rate)\n",
      "  Candidate 4: 4 votes (20.0% approval rate)\n",
      "  Candidate 5: 1 votes (5.0% approval rate)\n",
      "\n",
      "Total votes cast: 20\n",
      "Average approvals per voter: 1.00\n",
      "\n",
      "Top 3 candidates (by vote count): [3, 4, 2]\n",
      "Winner (randomly selected from top 3): Candidate 2\n",
      "Global utility (using true utility vectors): 157.8211\n",
      "Average utility per voter: 7.8911\n"
     ]
    }
   ],
   "source": [
    "# Example simulation\n",
    "n_voters = 20\n",
    "m_candidates = 5\n",
    "d_dimensions = 10\n",
    "budget = 20.0\n",
    "sparsity = 0.4  # 40% of dimensions zeroed out in voting vectors\n",
    "k = 3  # Top k candidates to consider for winner selection\n",
    "\n",
    "results = run_approval_voting_simulation(\n",
    "    n=n_voters,\n",
    "    m=m_candidates,\n",
    "    d=d_dimensions,\n",
    "    budget=budget,\n",
    "    sparsity=sparsity,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Approval Voting Simulation Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Voters: {n_voters}, Candidates: {m_candidates}, Dimensions: {d_dimensions}\")\n",
    "print(f\"Budget per candidate: {budget}, Voting vector sparsity: {sparsity}\")\n",
    "print(\"\\nVote counts for each candidate:\")\n",
    "for i, votes in enumerate(results['vote_counts']):\n",
    "    print(f\"  Candidate {i+1}: {votes} votes ({votes/n_voters*100:.1f}% approval rate)\")\n",
    "\n",
    "print(f\"\\nTotal votes cast: {np.sum(results['vote_counts'])}\")\n",
    "print(f\"Average approvals per voter: {np.sum(results['approval_matrix']) / n_voters:.2f}\")\n",
    "\n",
    "# Select winner from top k and compute global utility\n",
    "winner_idx, global_utility, top_k_indices = select_winner_and_compute_global_utility(\n",
    "    results['vote_counts'],\n",
    "    results['candidate_vectors'],\n",
    "    results['true_utility_vectors'],\n",
    "    k=k,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTop {k} candidates (by vote count): {[i+1 for i in top_k_indices]}\")\n",
    "print(f\"Winner (randomly selected from top {k}): Candidate {winner_idx+1}\")\n",
    "print(f\"Global utility (using true utility vectors): {global_utility:.4f}\")\n",
    "print(f\"Average utility per voter: {global_utility/n_voters:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c6d4edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clustered_voters(n, d, n_clusters=3, cluster_size_variance=0.2, sparsity=0.3, seed=None):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Generate cluster centers\n",
    "    cluster_centers = np.zeros((n_clusters, d))\n",
    "    dimensions_per_cluster = d // n_clusters\n",
    "    \n",
    "    for cluster_idx in range(n_clusters):\n",
    "        start_dim = cluster_idx * dimensions_per_cluster\n",
    "        end_dim = min((cluster_idx + 1) * dimensions_per_cluster, d)\n",
    "        cluster_centers[cluster_idx, start_dim:end_dim] = np.random.uniform(\n",
    "            0.5, 2.0, size=end_dim - start_dim\n",
    "        )\n",
    "\n",
    "    # Assign voters to clusters\n",
    "    cluster_sizes = np.random.multinomial(n, [1/n_clusters] * n_clusters)\n",
    "    cluster_sizes = cluster_sizes + 1\n",
    "    cluster_sizes = (cluster_sizes / cluster_sizes.sum() * n).astype(int)\n",
    "    cluster_sizes[-1] += n - cluster_sizes.sum()\n",
    "    \n",
    "    cluster_labels = []\n",
    "    for cluster_idx, size in enumerate(cluster_sizes):\n",
    "        cluster_labels.extend([cluster_idx] * size)\n",
    "    cluster_labels = np.array(cluster_labels)\n",
    "    np.random.shuffle(cluster_labels)\n",
    "\n",
    "    # NEW: choose zero indices per cluster, not per voter\n",
    "    num_zeros = int(d * sparsity)\n",
    "    cluster_zero_indices = [\n",
    "        np.random.choice(d, size=num_zeros, replace=False)\n",
    "        for _ in range(n_clusters)\n",
    "    ]\n",
    "\n",
    "    # Generate voting vectors\n",
    "    voting_vectors = np.zeros((n, d))\n",
    "    for i in range(n):\n",
    "        cluster_idx = cluster_labels[i]\n",
    "        center = cluster_centers[cluster_idx]\n",
    "        \n",
    "        noise = np.random.normal(0, 0.3, size=d)\n",
    "        voter_vec = np.maximum(center + noise, 0)\n",
    "        \n",
    "        # ZERO OUT SAME DIMENSIONS FOR ALL VOTERS IN A CLUSTER\n",
    "        voter_vec[cluster_zero_indices[cluster_idx]] = 0\n",
    "        \n",
    "        voting_vectors[i] = voter_vec\n",
    "\n",
    "    # True utility centers\n",
    "    true_utility_centers = np.zeros((n_clusters, d))\n",
    "    for cluster_idx in range(n_clusters):\n",
    "        start_dim = cluster_idx * dimensions_per_cluster\n",
    "        end_dim = min((cluster_idx + 1) * dimensions_per_cluster, d)\n",
    "        \n",
    "        true_utility_centers[cluster_idx, start_dim:end_dim] = np.random.uniform(\n",
    "            3.0, 8.0, size=end_dim - start_dim\n",
    "        )\n",
    "        \n",
    "        other_dims = np.ones(d, dtype=bool)\n",
    "        other_dims[start_dim:end_dim] = False\n",
    "        true_utility_centers[cluster_idx, other_dims] = np.random.uniform(\n",
    "            1.0, 4.0, size=np.sum(other_dims)\n",
    "        )\n",
    "\n",
    "    # True utility vectors (small noise)\n",
    "    true_utility_vectors = np.zeros((n, d))\n",
    "    for i in range(n):\n",
    "        cluster_idx = cluster_labels[i]\n",
    "        noise = np.random.normal(0, 0.5, size=d)\n",
    "        util_vec = np.maximum(true_utility_centers[cluster_idx] + noise, 0.1)\n",
    "        true_utility_vectors[i] = util_vec\n",
    "    \n",
    "    return true_utility_vectors, voting_vectors, cluster_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c01a80cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1: Clustered Voters (3 groups)\n",
      "============================================================\n",
      "Generated 30 voters in 3 clusters\n",
      "Cluster sizes: [8, 11, 11]\n",
      "\n",
      "============================================================\n",
      "OPTIMIZATION FOR ALL K VALUES\n",
      "============================================================\n",
      "Voters: 30, Candidates: 4, Dimensions: 6\n",
      "Budget: 10.0\n",
      "\n",
      "\n",
      "============================================================\n",
      "K = 1\n",
      "============================================================\n",
      "\n",
      "Optimizing 4 candidates for top-1 selection...\n",
      "Order: [1 3 2 4]\n",
      "All candidates converged after 6 iterations\n",
      "\n",
      "Running 200 simulations for k=1...\n",
      "Expected global utility for k=1: 171.3614  12.8771\n",
      "\n",
      "============================================================\n",
      "K = 2\n",
      "============================================================\n",
      "\n",
      "Optimizing 4 candidates for top-2 selection...\n",
      "Order: [1 3 2 4]\n",
      "All candidates converged after 2 iterations\n",
      "\n",
      "Running 200 simulations for k=2...\n",
      "Expected global utility for k=2: 271.9466  54.3344\n",
      "\n",
      "============================================================\n",
      "K = 3\n",
      "============================================================\n",
      "\n",
      "Optimizing 4 candidates for top-3 selection...\n",
      "Order: [1 3 2 4]\n",
      "All candidates converged after 2 iterations\n",
      "\n",
      "Running 200 simulations for k=3...\n",
      "Expected global utility for k=3: 216.2048  36.4721\n",
      "\n",
      "============================================================\n",
      "K = 4\n",
      "============================================================\n",
      "\n",
      "Optimizing 4 candidates for top-4 selection...\n",
      "Order: [1 3 2 4]\n",
      "All candidates converged after 1 iterations\n",
      "\n",
      "Running 200 simulations for k=4...\n",
      "Expected global utility for k=4: 178.7473  45.6662\n",
      "\n",
      "============================================================\n",
      "SUMMARY: Expected Global Utility by K\n",
      "============================================================\n",
      "\n",
      "k=1: 171.3614  12.8771\n",
      "k=2: 271.9466  54.3344 <-- OPTIMAL\n",
      "k=3: 216.2048  36.4721\n",
      "k=4: 178.7473  45.6662\n",
      "\n",
      "============================================================\n",
      "DETAILED RESULTS FOR K=2\n",
      "============================================================\n",
      "Optimized candidates for k=1:\n",
      "  Candidate 1: [-1. 15. -1. -1. -1. -1.]\n",
      "  Candidate 2: [-1.          1.27671897  4.76033811  4.75751636 -1.          1.20542656]\n",
      "  Candidate 3: [-1.          8.37540901 -1.          5.62459099 -1.         -1.        ]\n",
      "  Candidate 4: [ 4.76898426  9.23101574 -1.         -1.         -1.         -1.        ]\n",
      "Optimized candidates for k=2:\n",
      "  Candidate 1: [-0.01476075 -1.         -1.          6.58812206  6.42663868 -1.        ]\n",
      "  Candidate 2: [-1.          6.56297194  5.01500174  1.42202632 -1.         -1.        ]\n",
      "  Candidate 3: [1.66666667 1.66666667 1.66666667 1.66666667 1.66666667 1.66666667]\n",
      "  Candidate 4: [ 4.94370318  1.40279505  3.507985   -1.          0.02170216  1.1238146 ]\n",
      "Optimized candidates for k=3:\n",
      "  Candidate 1: [12.71396869 -1.         -1.         -1.         -1.          1.28603131]\n",
      "  Candidate 2: [ 2.22066496  1.32849547 -0.13589186 -0.18026859  0.30969443  6.45730559]\n",
      "  Candidate 3: [ 1.92498989 -0.46118728  2.95844833  1.15833184  1.87937632  2.54004091]\n",
      "  Candidate 4: [ 0.96121376  0.83531314  5.5640614  -0.05629586  0.07738391  2.61832365]\n",
      "Optimized candidates for k=4:\n",
      "  Candidate 1: [-0.17646109 -0.48746033  3.40764549  3.75938426  1.82889002  1.66800165]\n",
      "  Candidate 2: [ 5.92177322  3.54265459 -0.36237828 -0.48071624  0.8258518   0.55281491]\n",
      "  Candidate 3: [ 1.92498989 -0.46118728  2.95844833  1.15833184  1.87937632  2.54004091]\n",
      "  Candidate 4: [ 5.76728254  5.01187884  0.05103509 -0.33777517  0.46430346 -0.95672475]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================\n",
    "\n",
    "# Example 1: Simple clustered voters\n",
    "print(\"EXAMPLE 1: Clustered Voters (3 groups)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_voters = 30\n",
    "n_candidates = 4\n",
    "d_dimensions = 6\n",
    "budget = 10.0\n",
    "n_clusters = 3\n",
    "sparsity = 0.3\n",
    "\n",
    "# Generate clustered voters\n",
    "true_utility_vectors, voting_vectors, cluster_labels = generate_clustered_voters(\n",
    "    n=n_voters,\n",
    "    d=d_dimensions,\n",
    "    n_clusters=n_clusters,\n",
    "    cluster_size_variance=0.2,\n",
    "    sparsity=sparsity,\n",
    "    seed=2\n",
    ")\n",
    "\n",
    "print(f\"Generated {n_voters} voters in {n_clusters} clusters\")\n",
    "print(f\"Cluster sizes: {[np.sum(cluster_labels == i) for i in range(n_clusters)]}\")\n",
    "print()\n",
    "\n",
    "# Run optimization for all k values\n",
    "results_by_k = run_simulation_with_optimization_all_k(\n",
    "    voting_vectors=voting_vectors,\n",
    "    true_utility_vectors=true_utility_vectors,\n",
    "    n_candidates=n_candidates,\n",
    "    budget=budget,\n",
    "    n_simulations=200,  # Fewer simulations for faster example\n",
    "    learning_rate=0.05,\n",
    "    convergence_threshold=1e-2,\n",
    "    max_iterations=200,  # Fewer iterations for faster example\n",
    "    optimization_seed=456,\n",
    "    simulation_seed=789,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Access results for specific k\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETAILED RESULTS FOR K=2\")\n",
    "print(\"=\" * 60)\n",
    "for k in results_by_k.keys():\n",
    "    print(f\"Optimized candidates for k={k}:\")\n",
    "    for i, candidate in enumerate(results_by_k[k]['optimized_candidates']):\n",
    "        print(f\"  Candidate {i+1}: {candidate}\")\n",
    "        # print(f\"\\nExpected utility: {results_by_k[k]['expected_utility']:.4f}\")\n",
    "        # print(f\"Std deviation: {results_by_k[k]['std_utility']:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# # Example 2: Random voters (non-clustered)\n",
    "# print(\"\\n\\n\" + \"=\" * 60)\n",
    "# print(\"EXAMPLE 2: Random Voters (non-clustered)\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# n_voters = 25\n",
    "# n_candidates = 3\n",
    "# d_dimensions = 5\n",
    "# budget = 8.0\n",
    "# sparsity = 0.4\n",
    "\n",
    "# # Generate random voters\n",
    "# true_utility_vectors, voting_vectors = generate_voters(\n",
    "#     n=n_voters,\n",
    "#     d=d_dimensions,\n",
    "#     sparsity=sparsity,\n",
    "#     seed=999\n",
    "# )\n",
    "\n",
    "# print(f\"Generated {n_voters} random voters\")\n",
    "# print()\n",
    "\n",
    "# # Run optimization for all k values\n",
    "# results_by_k_random = run_simulation_with_optimization_all_k(\n",
    "#     voting_vectors=voting_vectors,\n",
    "#     true_utility_vectors=true_utility_vectors,\n",
    "#     n_candidates=n_candidates,\n",
    "#     budget=budget,\n",
    "#     n_simulations=150,\n",
    "#     learning_rate=0.05,\n",
    "#     convergence_threshold=1e-2,\n",
    "#     max_iterations=150,\n",
    "#     optimization_seed=111,\n",
    "#     simulation_seed=222,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# # Compare k=1 vs k=m (all candidates)\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"COMPARISON: k=1 vs k=m\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"k=1 (winner takes all): {results_by_k_random[1]['expected_utility']:.4f}\")\n",
    "# print(f\"k={n_candidates} (all candidates): {results_by_k_random[n_candidates]['expected_utility']:.4f}\")\n",
    "# improvement = results_by_k_random[1]['expected_utility'] - results_by_k_random[n_candidates]['expected_utility']\n",
    "# print(f\"Difference: {improvement:.4f} ({improvement/results_by_k_random[n_candidates]['expected_utility']*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6c728445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.11133361e-01 4.07890159e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.13055463e+00 1.15820800e+00]\n",
      " [0.00000000e+00 2.31303521e-01 7.64066520e-01 0.00000000e+00\n",
      "  4.40303403e-01 0.00000000e+00]\n",
      " [1.83402234e-01 1.43911776e-02 1.07575313e+00 0.00000000e+00\n",
      "  3.00109766e-01 0.00000000e+00]\n",
      " [1.04129153e+00 5.16548119e-01 1.30048899e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.52518873e-01]\n",
      " [1.21882716e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.78010300e-02]\n",
      " [0.00000000e+00 1.38766569e-02 1.12119104e+00 0.00000000e+00\n",
      "  1.57288929e-01 2.20583873e-01]\n",
      " [0.00000000e+00 2.52736884e-01 1.21003877e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.75346117e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.53302960e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.47410902e-01 3.74463876e-01 1.20332604e+00 0.00000000e+00\n",
      "  4.10170627e-01 3.65365690e-01]\n",
      " [0.00000000e+00 1.05266548e-01 0.00000000e+00 1.69882632e-01\n",
      "  1.19181410e+00 1.41751110e+00]\n",
      " [0.00000000e+00 3.12247186e-01 1.43863531e+00 0.00000000e+00\n",
      "  3.52059450e-01 0.00000000e+00]\n",
      " [3.48456447e-01 1.15823414e-01 0.00000000e+00 1.29927766e-01\n",
      "  1.03932577e+00 1.77109069e+00]\n",
      " [5.50599817e-01 1.32206962e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.03303681e+00 8.27431880e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.24163987e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.65131471e-01 0.00000000e+00 1.01806930e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.27147412e-01]\n",
      " [1.39374635e+00 9.17673447e-01 2.25589455e-01 0.00000000e+00\n",
      "  3.32742984e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.77499956e-01\n",
      "  1.07557473e+00 1.30145865e+00]\n",
      " [0.00000000e+00 2.53893568e-01 0.00000000e+00 3.79512526e-02\n",
      "  7.04908538e-01 9.19969996e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.91258396e-01\n",
      "  1.66832956e+00 8.66798236e-01]\n",
      " [2.08859394e-01 2.09224882e-01 0.00000000e+00 1.09784721e-03\n",
      "  1.06207744e+00 3.74618553e-01]\n",
      " [1.83043226e-01 1.27049070e-01 1.65985974e+00 0.00000000e+00\n",
      "  5.22543657e-01 0.00000000e+00]\n",
      " [0.00000000e+00 2.81449101e-01 1.18398984e+00 0.00000000e+00\n",
      "  3.74470939e-02 2.26950643e-01]\n",
      " [1.22642424e+00 6.88117042e-01 1.23260779e+00 0.00000000e+00\n",
      "  4.59528095e-01 0.00000000e+00]\n",
      " [1.26350841e+00 7.71113958e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.18956048e-01 0.00000000e+00]\n",
      " [9.75865678e-01 8.83739518e-01 4.00669851e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.54311215e-01]\n",
      " [1.40282988e+00 7.28075938e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.07740000e-01 1.86666124e-01]\n",
      " [1.44222694e+00 7.66400452e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.41342992e-01]\n",
      " [5.41229421e-02 1.65949282e-01 0.00000000e+00 0.00000000e+00\n",
      "  7.85250820e-01 8.67545490e-01]\n",
      " [0.00000000e+00 4.50431075e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.32981813e+00 1.21596763e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 9.91464192e-02\n",
      "  1.03584374e+00 5.90501601e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(voting_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0a98d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIAGNOSTIC FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def diagnose_nan_issues(candidate_vectors, voting_vectors, true_utility_vectors):\n",
    "    \"\"\"\n",
    "    Run diagnostics to find sources of NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    candidate_vectors : ndarray\n",
    "        Candidate policy vectors\n",
    "    voting_vectors : ndarray\n",
    "        Voting vectors\n",
    "    true_utility_vectors : ndarray\n",
    "        True utility vectors\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Diagnostic results\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"NaN DIAGNOSTIC REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    issues = {\n",
    "        'nan_in_candidates': False,\n",
    "        'nan_in_voting': False,\n",
    "        'nan_in_true_utility': False,\n",
    "        'nan_in_utilities': False,\n",
    "        'nan_in_gradients': False,\n",
    "        'extreme_values': False\n",
    "    }\n",
    "    \n",
    "    # Check inputs\n",
    "    if np.any(np.isnan(candidate_vectors)):\n",
    "        issues['nan_in_candidates'] = True\n",
    "        print(f\" Found {np.sum(np.isnan(candidate_vectors))} NaN values in candidate_vectors\")\n",
    "    else:\n",
    "        print(f\" No NaN in candidate_vectors\")\n",
    "    \n",
    "    if np.any(np.isnan(voting_vectors)):\n",
    "        issues['nan_in_voting'] = True\n",
    "        print(f\" Found {np.sum(np.isnan(voting_vectors))} NaN values in voting_vectors\")\n",
    "    else:\n",
    "        print(f\" No NaN in voting_vectors\")\n",
    "    \n",
    "    if np.any(np.isnan(true_utility_vectors)):\n",
    "        issues['nan_in_true_utility'] = True\n",
    "        print(f\" Found {np.sum(np.isnan(true_utility_vectors))} NaN values in true_utility_vectors\")\n",
    "    else:\n",
    "        print(f\" No NaN in true_utility_vectors\")\n",
    "    \n",
    "    # Check utilities\n",
    "    print(\"\\nTesting utility calculations...\")\n",
    "    nan_count = 0\n",
    "    for i, candidate in enumerate(candidate_vectors):\n",
    "        for j, voter in enumerate(voting_vectors):\n",
    "            util = utility_function(candidate, voter)\n",
    "            if np.isnan(util):\n",
    "                nan_count += 1\n",
    "                if nan_count <= 3:  # Show first 3\n",
    "                    print(f\"  NaN utility: candidate {i}, voter {j}\")\n",
    "    \n",
    "    if nan_count > 0:\n",
    "        issues['nan_in_utilities'] = True\n",
    "        print(f\" Found {nan_count} NaN utilities\")\n",
    "    else:\n",
    "        print(f\" All utilities are valid\")\n",
    "    \n",
    "    # Check gradients\n",
    "    print(\"\\nTesting gradient calculations...\")\n",
    "    nan_count = 0\n",
    "    for i, candidate in enumerate(candidate_vectors):\n",
    "        for j, voter in enumerate(voting_vectors):\n",
    "            grad = utility_gradient(candidate, voter)\n",
    "            if np.any(np.isnan(grad)):\n",
    "                nan_count += 1\n",
    "                if nan_count <= 3:\n",
    "                    print(f\"  NaN gradient: candidate {i}, voter {j}\")\n",
    "    \n",
    "    if nan_count > 0:\n",
    "        issues['nan_in_gradients'] = True\n",
    "        print(f\" Found {nan_count} NaN gradients\")\n",
    "    else:\n",
    "        print(f\" All gradients are valid\")\n",
    "    \n",
    "    # Check for extreme values\n",
    "    print(\"\\nChecking for extreme values...\")\n",
    "    if np.any(np.abs(candidate_vectors) > 1000):\n",
    "        issues['extreme_values'] = True\n",
    "        print(f\" Extreme values in candidates: max={np.max(np.abs(candidate_vectors))}\")\n",
    "    else:\n",
    "        print(f\" No extreme values\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    return issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9425e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "EXAMPLE 3: Comprehensive Analysis Across All K\n",
      "============================================================\n",
      "Setup: 40 voters, 6 candidates, 8 dimensions\n",
      "Clusters: [17, 10, 13]\n",
      "\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE RESULTS TABLE\n",
      "================================================================================\n",
      "k     Expected Utility     Std Dev         Relative to k=1     \n",
      "--------------------------------------------------------------------------------\n",
      "1     170.1378             56.0847           0.00%\n",
      "2     273.5433             0.0000           60.78%\n",
      "3     304.5436             7.5551           79.00%\n",
      "4     375.5953             8.4521          120.76% *** OPTIMAL ***\n",
      "5     351.5286             0.0000          106.61%\n",
      "6     311.2745             0.0000           82.95%\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Comprehensive analysis across all k values\n",
    "print(\"\\n\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE 3: Comprehensive Analysis Across All K\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_voters = 40\n",
    "n_candidates = 6\n",
    "d_dimensions = 8\n",
    "budget = 12.0\n",
    "sparsity = 0.35\n",
    "\n",
    "# Generate clustered voters\n",
    "true_utility_vectors, voting_vectors, cluster_labels = generate_clustered_voters(\n",
    "    n=n_voters,\n",
    "    d=d_dimensions,\n",
    "    n_clusters=3,\n",
    "    cluster_size_variance=0.2,\n",
    "    sparsity=sparsity,\n",
    "    seed=555\n",
    ")\n",
    "\n",
    "print(f\"Setup: {n_voters} voters, {n_candidates} candidates, {d_dimensions} dimensions\")\n",
    "print(f\"Clusters: {[np.sum(cluster_labels == i) for i in range(3)]}\")\n",
    "print()\n",
    "\n",
    "# Run optimization for all k values\n",
    "results_comprehensive = run_simulation_with_optimization_all_k(\n",
    "    voting_vectors=voting_vectors,\n",
    "    true_utility_vectors=true_utility_vectors,\n",
    "    n_candidates=n_candidates,\n",
    "    budget=budget,\n",
    "    n_simulations=300,\n",
    "    learning_rate=0.05,\n",
    "    convergence_threshold=1e-2,\n",
    "    max_iterations=250,\n",
    "    optimization_seed=777,\n",
    "    simulation_seed=888,\n",
    "    verbose=False  # Set to False for cleaner output\n",
    ")\n",
    "\n",
    "# Display comprehensive results table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPREHENSIVE RESULTS TABLE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'k':<5} {'Expected Utility':<20} {'Std Dev':<15} {'Relative to k=1':<20}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "baseline_utility = results_comprehensive[1]['expected_utility']\n",
    "optimal_k = max(results_comprehensive.keys(), \n",
    "                key=lambda k: results_comprehensive[k]['expected_utility'])\n",
    "\n",
    "for k in range(1, n_candidates + 1):\n",
    "    exp_util = results_comprehensive[k]['expected_utility']\n",
    "    std_util = results_comprehensive[k]['std_utility']\n",
    "    relative_pct = ((exp_util - baseline_utility) / baseline_utility * 100)\n",
    "    \n",
    "    marker = \" *** OPTIMAL ***\" if k == optimal_k else \"\"\n",
    "    \n",
    "    print(f\"{k:<5} {exp_util:<20.4f} {std_util:<15.4f} {relative_pct:>6.2f}%{marker}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# # Statistical analysis\n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"STATISTICAL ANALYSIS\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# utilities_list = [results_comprehensive[k]['expected_utility'] for k in range(1, n_candidates + 1)]\n",
    "# max_util = max(utilities_list)\n",
    "# min_util = min(utilities_list)\n",
    "# avg_util = np.mean(utilities_list)\n",
    "\n",
    "# print(f\"Maximum utility: {max_util:.4f} (at k={optimal_k})\")\n",
    "# print(f\"Minimum utility: {min_util:.4f} (at k={np.argmin(utilities_list) + 1})\")\n",
    "# print(f\"Average utility: {avg_util:.4f}\")\n",
    "# print(f\"Range: {max_util - min_util:.4f} ({(max_util - min_util)/min_util * 100:.2f}% variation)\")\n",
    "\n",
    "# # Show how utility changes with k\n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"UTILITY TREND\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# for k in range(1, n_candidates + 1):\n",
    "#     util = results_comprehensive[k]['expected_utility']\n",
    "#     bar_length = int((util - min_util) / (max_util - min_util) * 50) if max_util != min_util else 25\n",
    "#     bar = \"\" * bar_length\n",
    "#     print(f\"k={k}: {bar} {util:.2f}\")\n",
    "\n",
    "# # Examine optimized candidates for different k values\n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"OPTIMIZED CANDIDATE STRATEGIES\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# for k_sample in [1, n_candidates // 2, n_candidates]:\n",
    "#     print(f\"\\nk={k_sample} - Optimized Candidates:\")\n",
    "#     for i, candidate in enumerate(results_comprehensive[k_sample]['optimized_candidates']):\n",
    "#         print(f\"  Candidate {i+1}: {np.round(candidate, 2)}\")\n",
    "#         print(f\"    Budget: {np.sum(candidate):.4f}, Non-negative dims: {np.sum(candidate > -0.99)}/{d_dimensions}\")\n",
    "\n",
    "# # Compare variance across k\n",
    "# print(\"\\n\" + \"=\" * 80)\n",
    "# print(\"VARIANCE ANALYSIS\")\n",
    "# print(\"=\" * 80)\n",
    "# print(f\"{'k':<5} {'Coefficient of Variation':<25} {'Interpretation':<30}\")\n",
    "# print(\"-\" * 80)\n",
    "\n",
    "# for k in range(1, n_candidates + 1):\n",
    "#     exp_util = results_comprehensive[k]['expected_utility']\n",
    "#     std_util = results_comprehensive[k]['std_utility']\n",
    "#     cv = (std_util / exp_util * 100) if exp_util > 0 else 0\n",
    "    \n",
    "#     if cv < 5:\n",
    "#         interpretation = \"Very stable\"\n",
    "#     elif cv < 10:\n",
    "#         interpretation = \"Stable\"\n",
    "#     elif cv < 20:\n",
    "#         interpretation = \"Moderate variance\"\n",
    "#     else:\n",
    "#         interpretation = \"High variance\"\n",
    "    \n",
    "#     print(f\"{k:<5} {cv:>6.2f}%{'':<18} {interpretation:<30}\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
